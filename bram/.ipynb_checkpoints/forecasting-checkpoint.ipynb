{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change these to try this notebook out# chang \n",
    "BUCKET = 'atos-asl'\n",
    "PROJECT = 'qwiklabs-gcp-aebfb78fe0f1b1d1'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([[0.0] for i in range(0, 24)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir ./train\n",
    "touch ./train/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./train/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./train/model.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "TIMESERIES_COL = 'price'\n",
    "N_OUTPUTS = 1  # in each sequence, 1-49 are features, and 50 is label\n",
    "SEQ_LEN = None\n",
    "DEFAULTS =None\n",
    "N_INPUTS = None\n",
    "\n",
    "CSV_COLUMNS = [ 'prediction_date',\n",
    "               'avg_wind_speed_100m',\n",
    "               'avg_wind_direction_100m',\n",
    "               'avg_temperature',\n",
    "               'avg_air_density',\n",
    "               'avg_pressure',\n",
    "               'avg_precipitation',\n",
    "               'avg_wind_gust',\n",
    "               'avg_radiation',\n",
    "               'avg_wind_speed',\n",
    "               'avg_wind_direction',\n",
    "               'price',\n",
    "               'key'\n",
    "              ]\n",
    "\n",
    "LABEL_COLUMN = 'price'\n",
    "NUMBER_OF_BUCKET = 42 # Number of week # Number of days: 289\n",
    "\n",
    "# Set default values for each CSV column\n",
    "\n",
    "\n",
    "def init(hparams):\n",
    "    global SEQ_LEN, DEFAULTS, N_INPUTS\n",
    "    SEQ_LEN = hparams['sequence_length']\n",
    "    DEFAULTS = [[0.0] for x in range(0, SEQ_LEN)]\n",
    "    N_INPUTS = SEQ_LEN - N_OUTPUTS\n",
    "\n",
    "\n",
    "def linear_model(features, mode, params):\n",
    "    X = features[TIMESERIES_COL]\n",
    "    predictions = tf.layers.dense(X, 1, activation=None)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def dnn_model(features, mode, params):\n",
    "    X = features[TIMESERIES_COL]\n",
    "    h1 = tf.layers.dense(X, 10, activation=tf.nn.relu)\n",
    "    h2 = tf.layers.dense(h1, 3, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h2, 1, activation=None)  # linear output: regression\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def cnn_model(features, mode, params):\n",
    "    X = tf.reshape(features[TIMESERIES_COL],\n",
    "                   [-1, N_INPUTS, 1])  # as a 1D \"sequence\" with only one time-series observation (height)\n",
    "    c1 = tf.layers.conv1d(X, filters=N_INPUTS // 2,\n",
    "                          kernel_size=3, strides=1,\n",
    "                          padding='same', activation=tf.nn.relu)\n",
    "    p1 = tf.layers.max_pooling1d(c1, pool_size=2, strides=2)\n",
    "\n",
    "    c2 = tf.layers.conv1d(p1, filters=N_INPUTS // 2,\n",
    "                          kernel_size=3, strides=1,\n",
    "                          padding='same', activation=tf.nn.relu)\n",
    "    p2 = tf.layers.max_pooling1d(c2, pool_size=2, strides=2)\n",
    "\n",
    "    outlen = p2.shape[1] * p2.shape[2]\n",
    "    c2flat = tf.reshape(p2, [-1, outlen])\n",
    "    h1 = tf.layers.dense(c2flat, 3, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h1, 1, activation=None)  # linear output: regression\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def rnn_model(features, mode, params):\n",
    "    CELL_SIZE = N_INPUTS // 3  # size of the internal state in each of the cells\n",
    "\n",
    "    # 1. dynamic_rnn needs 3D shape: [BATCH_SIZE, N_INPUTS, 1]\n",
    "    x = tf.reshape(features[TIMESERIES_COL], [-1, N_INPUTS, 1])\n",
    "\n",
    "    # 2. configure the RNN\n",
    "    cell = tf.nn.rnn_cell.GRUCell(CELL_SIZE)\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\n",
    "\n",
    "    # 3. pass rnn output through a dense layer\n",
    "    h1 = tf.layers.dense(state, N_INPUTS // 2, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h1, 1, activation=None)  # (?, 1)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# 2-layer RNN\n",
    "def rnn2_model(features, mode, params):\n",
    "    # dynamic_rnn needs 3D shape: [BATCH_SIZE, N_INPUTS, 1]\n",
    "    x = tf.reshape(features[TIMESERIES_COL], [-1, N_INPUTS, 1])\n",
    "\n",
    "    # 2. configure the RNN\n",
    "    cell1 = tf.nn.rnn_cell.GRUCell(N_INPUTS * 2)\n",
    "    cell2 = tf.nn.rnn_cell.GRUCell(N_INPUTS // 2)\n",
    "    cells = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
    "    outputs, state = tf.nn.dynamic_rnn(cells, x, dtype=tf.float32)\n",
    "    # 'state' is now a tuple containing the final state of each cell layer\n",
    "    # we use state[1] below to extract the final state of the final layer\n",
    "    \n",
    "    # 3. pass rnn output through a dense layer\n",
    "    h1 = tf.layers.dense(state[1], cells.output_size // 2, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h1, 1, activation=None)  # (?, 1)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# create N-1 predictions\n",
    "def rnnN_model(features, mode, params):\n",
    "    # dynamic_rnn needs 3D shape: [BATCH_SIZE, N_INPUTS, 1]\n",
    "    x = tf.reshape(features[TIMESERIES_COL], [-1, N_INPUTS, 1])\n",
    "\n",
    "    # 2. configure the RNN\n",
    "    cell1 = tf.nn.rnn_cell.GRUCell(N_INPUTS * 2)\n",
    "    cell2 = tf.nn.rnn_cell.GRUCell(N_INPUTS // 2)\n",
    "    cells = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
    "    outputs, state = tf.nn.dynamic_rnn(cells, x, dtype=tf.float32)\n",
    "    # 'outputs' contains the state of the final layer for every time step\n",
    "    # not just the last time step (?,N_INPUTS, final cell size)\n",
    "    \n",
    "    # 3. pass state for each time step through a DNN, to get a prediction\n",
    "    # for each time step \n",
    "    h1 = tf.layers.dense(outputs, cells.output_size, activation=tf.nn.relu)\n",
    "    h2 = tf.layers.dense(h1, cells.output_size // 2, activation=tf.nn.relu)\n",
    "    predictions = tf.layers.dense(h2, 1, activation=None)  # (?, N_INPUTS, 1)\n",
    "    predictions = tf.reshape(predictions, [-1, N_INPUTS])\n",
    "    return predictions # return prediction for each time step\n",
    "\n",
    "\n",
    "# read data and convert to needed format\n",
    "def read_dataset(filename, mode, batch_size=512):\n",
    "    def _input_fn():\n",
    "        def decode_csv(row):\n",
    "            # row is a string tensor containing the contents of one row\n",
    "            features = tf.decode_csv(row, record_defaults=DEFAULTS)  # string tensor -> list of 50 rank 0 float tensors\n",
    "            label = features.pop()  # remove last feature and use as label\n",
    "            features = tf.stack(features)  # list of rank 0 tensors -> single rank 1 tensor\n",
    "            return {TIMESERIES_COL: features}, label\n",
    "\n",
    "        # Create list of file names that match \"glob\" pattern (i.e. data_file_*.csv)\n",
    "        dataset = tf.data.Dataset.list_files(filename)\n",
    "        # Read in data from files\n",
    "        dataset = dataset.flat_map(tf.data.TextLineDataset)\n",
    "        # Parse text lines as comma-separated values (CSV)\n",
    "        dataset = dataset.map(decode_csv)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None  # loop indefinitely\n",
    "\n",
    "        else:\n",
    "            num_epochs = 1  # end-of-input after this\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "    return _input_fn\n",
    "\n",
    "\n",
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        TIMESERIES_COL: tf.placeholder(tf.float32, [None, N_INPUTS])\n",
    "    }\n",
    "\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    features[TIMESERIES_COL] = tf.squeeze(features[TIMESERIES_COL], axis=[2])\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
    "\n",
    "\n",
    "def compute_errors(features, labels, predictions):\n",
    "    labels = tf.expand_dims(labels, -1)  # rank 1 -> rank 2 to match rank of predictions\n",
    "\n",
    "    if predictions.shape[1] == 1:\n",
    "        loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "        rmse = tf.metrics.root_mean_squared_error(labels, predictions)\n",
    "        return loss, rmse\n",
    "    else:\n",
    "        # one prediction for every input in sequence\n",
    "        # get 1-N of (x + label)\n",
    "        labelsN = tf.concat([features[TIMESERIES_COL], labels], axis=1)\n",
    "        labelsN = labelsN[:, 1:]\n",
    "        # loss is computed from the last 1/3 of the series\n",
    "        N = (2 * N_INPUTS) // 3\n",
    "        loss = tf.losses.mean_squared_error(labelsN[:, N:], predictions[:, N:])\n",
    "        # rmse is computed from last prediction and last label\n",
    "        lastPred = predictions[:, -1]\n",
    "        rmse = tf.metrics.root_mean_squared_error(labels, lastPred)\n",
    "        return loss, rmse\n",
    "\n",
    "# RMSE when predicting same as last value\n",
    "def same_as_last_benchmark(features, labels):\n",
    "    predictions = features[TIMESERIES_COL][:,-1] # last value in input sequence\n",
    "    return tf.metrics.root_mean_squared_error(labels, predictions)\n",
    "\n",
    "\n",
    "# create the inference model\n",
    "def sequence_regressor(features, labels, mode, params):\n",
    "    # 1. run the appropriate model\n",
    "    model_functions = {\n",
    "        'linear': linear_model,\n",
    "        'dnn': dnn_model,\n",
    "        'cnn': cnn_model,\n",
    "        'rnn': rnn_model,\n",
    "        'rnn2': rnn2_model,\n",
    "        'rnnN': rnnN_model}\n",
    "    model_function = model_functions[params['model']]\n",
    "    predictions = model_function(features, mode, params)\n",
    "\n",
    "    # 2. loss function, training/eval ops\n",
    "    loss = None\n",
    "    train_op = None\n",
    "    eval_metric_ops = None\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        loss, rmse = compute_errors(features, labels, predictions)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # this is needed for batch normalization, but has no effect otherwise\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                # 2b. set up training operation\n",
    "                train_op = tf.contrib.layers.optimize_loss(\n",
    "                    loss,\n",
    "                    tf.train.get_global_step(),\n",
    "                    learning_rate=params['learning_rate'],\n",
    "                    optimizer=\"Adam\")\n",
    "\n",
    "        # 2c. eval metric\n",
    "        eval_metric_ops = {\n",
    "            \"RMSE\": rmse,\n",
    "            \"RMSE_same_as_last\": same_as_last_benchmark(features, labels),\n",
    "        }\n",
    "\n",
    "    # 3. Create predictions\n",
    "    if predictions.shape[1] != 1:\n",
    "        predictions = predictions[:, -1]  # last predicted value\n",
    "    predictions_dict = {\"predicted\": predictions}\n",
    "\n",
    "    # 4. return EstimatorSpec\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs={\n",
    "            'predictions': tf.estimator.export.PredictOutput(predictions_dict)}\n",
    "    )\n",
    "\n",
    "\n",
    "def train_and_evaluate(output_dir, hparams):\n",
    "    get_train = read_dataset(hparams['train_data_path'],\n",
    "                             tf.estimator.ModeKeys.TRAIN,\n",
    "                             hparams['train_batch_size'])\n",
    "    get_valid = read_dataset(hparams['eval_data_path'],\n",
    "                             tf.estimator.ModeKeys.EVAL,\n",
    "                             1000)\n",
    "    estimator = tf.estimator.Estimator(model_fn=sequence_regressor,\n",
    "                                       params=hparams,\n",
    "                                       config=tf.estimator.RunConfig(\n",
    "                                           save_summary_steps=50,\n",
    "                                           save_checkpoints_secs=\n",
    "                                           hparams['min_eval_frequency']),\n",
    "                                       model_dir=output_dir)\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=get_train,\n",
    "                                        max_steps=hparams['train_steps'])\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=get_valid,\n",
    "                                      steps=None,\n",
    "                                      exporters=exporter,\n",
    "                                      start_delay_secs=hparams['eval_delay_secs'],\n",
    "                                      throttle_secs=hparams['min_eval_frequency'])\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./train/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./train/task.py\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Example implementation of code to run on the Cloud ML service.\n",
    "\"\"\"\n",
    "\n",
    "import traceback\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from . import model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  # Input Arguments\n",
    "  parser.add_argument(\n",
    "      '--train_data_path',\n",
    "      help='GCS or local path to training data',\n",
    "      required=True\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--eval_data_path',\n",
    "      help='GCS or local path to evaluation data',\n",
    "      required=True\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--train_batch_size',\n",
    "      help='Batch size for training steps',\n",
    "      type=int,\n",
    "      default=100\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--learning_rate',\n",
    "      help='Initial learning rate for training',\n",
    "      type=float,\n",
    "      default=0.01\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--train_steps',\n",
    "      help=\"\"\"\\\n",
    "      Steps to run the training job for. A step is one batch-size,\\\n",
    "      \"\"\",\n",
    "      type=int,\n",
    "      default=0\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--sequence_length',\n",
    "      help=\"\"\"\\\n",
    "      This model works with fixed length sequences. 1-(N-1) are inputs, last is output\n",
    "      \"\"\",\n",
    "      type=int,\n",
    "      default=10\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--output_dir',\n",
    "      help='GCS location to write checkpoints and export models',\n",
    "      required=True\n",
    "  )\n",
    "  model_names = [name.replace('_model','') \\\n",
    "                   for name in dir(model) \\\n",
    "                     if name.endswith('_model')]\n",
    "  parser.add_argument(\n",
    "      '--model',\n",
    "      help='Type of model. Supported types are {}'.format(model_names),\n",
    "      required=True\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--job-dir',\n",
    "      help='this model ignores this field, but it is required by gcloud',\n",
    "      default='junk'\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--eval_delay_secs',\n",
    "      help='How long to wait before running first evaluation',\n",
    "      default=10,\n",
    "      type=int\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      '--min_eval_frequency',\n",
    "      help='Minimum number of training steps between evaluations',\n",
    "      default=60,\n",
    "      type=int\n",
    "  )\n",
    "\n",
    "  args = parser.parse_args()\n",
    "  hparams = args.__dict__\n",
    "  \n",
    "  # unused args provided by service\n",
    "  hparams.pop('job_dir', None)\n",
    "  hparams.pop('job-dir', None)\n",
    "\n",
    "  output_dir = hparams.pop('output_dir')\n",
    "\n",
    "  # Append trial_id to path if we are doing hptuning\n",
    "  # This code can be removed if you are not using hyperparameter tuning\n",
    "  output_dir = os.path.join(\n",
    "      output_dir,\n",
    "      json.loads(\n",
    "          os.environ.get('TF_CONFIG', '{}')\n",
    "      ).get('task', {}).get('trial', '')\n",
    "  )\n",
    "\n",
    "  # calculate train_steps if not provided\n",
    "  if hparams['train_steps'] < 1:\n",
    "     # 1,000 steps at batch_size of 100\n",
    "     hparams['train_steps'] = (1000 * 100) // hparams['train_batch_size']\n",
    "     print (\"Training for {} steps\".format(hparams['train_steps']))\n",
    "\n",
    "  model.init(hparams)\n",
    "\n",
    "  # Run the training job\n",
    "  model.train_and_evaluate(output_dir, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf ../test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  model.py  task.py\r\n"
     ]
    }
   ],
   "source": [
    "! ls ./train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 30, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe6d0056150>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '../test', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 30 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expect 10 fields but have 24 in record 0\n\t [[Node: DecodeCSV = DecodeCSV[OUT_TYPE=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], field_delim=\",\", na_value=\"\", use_quote_delim=true](arg0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_1, DecodeCSV/record_defaults_2, DecodeCSV/record_defaults_3, DecodeCSV/record_defaults_4, DecodeCSV/record_defaults_5, DecodeCSV/record_defaults_6, DecodeCSV/record_defaults_7, DecodeCSV/record_defaults_8, DecodeCSV/record_defaults_9)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,9], [?]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-a1b2dbcfc238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence_length'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-2b0e3078b437>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(output_dir, hparams)\u001b[0m\n\u001b[1;32m    295\u001b[0m                                       \u001b[0mstart_delay_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eval_delay_secs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                                       throttle_secs=hparams['min_eval_frequency'])\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/estimator/training.pyc\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    437\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m   \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/estimator/training.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    517\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/estimator/training.pyc\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    648\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m           hooks=train_hooks)\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m       \u001b[0;31m# Final export signal: For any eval result with global_step >= train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    857\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m    858\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1057\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    565\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1044\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1117\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py2env/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expect 10 fields but have 24 in record 0\n\t [[Node: DecodeCSV = DecodeCSV[OUT_TYPE=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], field_delim=\",\", na_value=\"\", use_quote_delim=true](arg0, DecodeCSV/record_defaults_0, DecodeCSV/record_defaults_1, DecodeCSV/record_defaults_2, DecodeCSV/record_defaults_3, DecodeCSV/record_defaults_4, DecodeCSV/record_defaults_5, DecodeCSV/record_defaults_6, DecodeCSV/record_defaults_7, DecodeCSV/record_defaults_8, DecodeCSV/record_defaults_9)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,9], [?]], output_types=[DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]"
     ]
    }
   ],
   "source": [
    "hparams = dict()\n",
    "hparams['eval_delay_secs'] = 30\n",
    "hparams['min_eval_frequency'] = 30\n",
    "hparams['train_data_path'] = './data/timeserie_price_daily_train.csv'\n",
    "hparams['eval_data_path'] = './data/timeserie_price_daily_eval.csv'\n",
    "hparams['train_batch_size'] = 140\n",
    "hparams['train_steps'] = 1000\n",
    "hparams['model'] = 'rnnN'\n",
    "hparams['learning_rate'] = 0.01\n",
    "hparams['sequence_length'] = 24\n",
    "init(hparams)\n",
    "train_and_evaluate('../test', hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py2env/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "INFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {}, u'job': {u'args': [u'--train_data_path=/content/datalab/energy_forcasing/bram/data/timeserie_price_daily_train.csv', u'--eval_data_path=/content/datalab/energy_forcasing/bram/data/timeserie_price_daily_eval.csv', u'--output_dir=/content/datalab/energy_forcasing/bram/trained/energy_forecast', u'--model=linear', u'--train_steps=10', u'--sequence_length=24'], u'job_name': u'train.task'}, u'task': {}}\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 60, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6438a2acd0>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/content/datalab/energy_forcasing/bram/trained/energy_forecast/', '_global_id_in_cluster': 0, '_save_summary_steps': 50}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 60 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Tensor(\"IteratorGetNext:0\", shape=(?, 23), dtype=float32, device=/device:CPU:0)\n",
      "INFO:tensorflow:(?, 23)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-09-17 22:28:17.040188: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /content/datalab/energy_forcasing/bram/trained/energy_forecast/model.ckpt.\n",
      "INFO:tensorflow:loss = 844.13, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /content/datalab/energy_forcasing/bram/trained/energy_forecast/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 112.79835.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Tensor(\"IteratorGetNext:0\", shape=(?, 23), dtype=float32, device=/device:CPU:0)\n",
      "INFO:tensorflow:(?, 23)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-17-22:28:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/energy_forcasing/bram/trained/energy_forecast/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-17-22:28:17\n",
      "INFO:tensorflow:Saving dict for global step 10: RMSE = 15.035352, RMSE_same_as_last = 10.128356, global_step = 10, loss = 226.0618\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Tensor(\"Squeeze:0\", shape=(?, 23), dtype=float32)\n",
      "INFO:tensorflow:(?, 23)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'predictions']\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/energy_forcasing/bram/trained/energy_forecast/model.ckpt-10\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /content/datalab/energy_forcasing/bram/trained/energy_forecast/export/exporter/temp-1537223298/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "DATADIR=$(pwd)/data\n",
    "OUTDIR=$(pwd)/trained/energy_forecast\n",
    "SEQ_LEN=24\n",
    "rm -rf $OUTDIR\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=train.task \\\n",
    "   --package-path=${PWD}/train \\\n",
    "   -- \\\n",
    "   --train_data_path=\"${DATADIR}/timeserie_price_daily_train_fix.csv\" \\\n",
    "   --eval_data_path=\"${DATADIR}/timeserie_price_daily_eval_fix.csv\"  \\\n",
    "   --output_dir=${OUTDIR} \\\n",
    "   --model=linear \\\n",
    "   --train_steps=1000 \\\n",
    "   --sequence_length=$SEQ_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: The mb command requires a URL that specifies a bucket.\n",
      "\"gs://atos-asl/bram/daily\" is not valid.\n",
      "Removing gs://atos-asl/bram/daily/timeserie_price_daily_eval.csv#1537223524383379...\n",
      "Removing gs://atos-asl/bram/daily/timeserie_price_daily_train.csv#1537223524393510...\n",
      "/ [1/2 objects]  50% Done                                                       \r",
      "/ [2/2 objects] 100% Done                                                       \r\n",
      "Operation completed over 2 objects.                                              \n",
      "Copying file://data/timeserie_price_daily_eval.csv [Content-Type=text/csv]...\n",
      "Copying file://data/timeserie_price_daily_train.csv [Content-Type=text/csv]...\n",
      "/ [0/2 files][    0.0 B/ 36.5 KiB]   0% Done                                    \r",
      "/ [0/2 files][    0.0 B/ 36.5 KiB]   0% Done                                    \r",
      "/ [1/2 files][ 36.5 KiB/ 36.5 KiB]  99% Done                                    \r",
      "/ [2/2 files][ 36.5 KiB/ 36.5 KiB] 100% Done                                    \r\n",
      "Operation completed over 2 objects/36.5 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gsutil mkdir gs://${BUCKET}/bram/daily\n",
    "gsutil -m rm -rf gs://${BUCKET}/bram/daily/*\n",
    "gsutil -m cp data/timeserie_price_daily_*.csv gs://${BUCKET}/bram/daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!echo $TFVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobId: brem_energy_forecast_linear_180917_233043\n",
      "state: QUEUED\n",
      "jobId: brem_energy_forecast_dnn_180917_233048\n",
      "state: QUEUED\n",
      "jobId: brem_energy_forecast_cnn_180917_233052\n",
      "state: QUEUED\n",
      "jobId: brem_energy_forecast_rnn_180917_233057\n",
      "state: QUEUED\n",
      "jobId: brem_energy_forecast_rnn2_180917_233102\n",
      "state: QUEUED\n",
      "jobId: brem_energy_forecast_rnnN_180917_233106\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing gs://atos-asl/bram/energy_forecast/linear/#1537226479516691...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/checkpoint#1537226481759749...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/eval/#1537226464206678...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/eval/events.out.tfevents.1537226464.cmle-training-13253099377514018438#1537226485203017...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/events.out.tfevents.1537226453.cmle-training-13253099377514018438#1537226483328912...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/export/#1537226467799316...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/export/exporter/#1537226468087350...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/export/exporter/1537226465/#1537226474550209...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/export/exporter/1537226465/saved_model.pb#1537226474974475...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/export/exporter/1537226465/variables/#1537226475279277...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/export/exporter/1537226465/variables/variables.data-00000-of-00001#1537226475604585...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/export/exporter/1537226465/variables/variables.index#1537226475929327...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/export/exporter/1537226485/#1537226492034622...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/export/exporter/1537226485/saved_model.pb#1537226492364193...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/export/exporter/1537226485/variables/#1537226492848049...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/export/exporter/1537226485/variables/variables.data-00000-of-00001#1537226493309968...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/export/exporter/1537226485/variables/variables.index#1537226493645563...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/graph.pbtxt#1537226455788480...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/model.ckpt-1.data-00000-of-00001#1537226459468691...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/model.ckpt-1.index#1537226459982325...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/model.ckpt-1.meta#1537226461994758...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/model.ckpt-30.data-00000-of-00001#1537226480074610...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/model.ckpt-30.index#1537226480723235...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/model.ckpt-30.meta#1537226482697305...\n",
      "Removing gs://atos-asl/bram/energy_forecast/linear/packages/cdc56516e8e91c04f987bf1ffe7bdfc1e9a14a9ca93ce2a30191750b3af0b159/train-0.0.0.tar.gz#1537226368905346...\n",
      "/ [1/25 objects]   4% Done                                                      \r",
      "/ [2/25 objects]   8% Done                                                      \r",
      "/ [3/25 objects]  12% Done                                                      \r",
      "/ [4/25 objects]  16% Done                                                      \r",
      "/ [5/25 objects]  20% Done                                                      \r",
      "/ [6/25 objects]  24% Done                                                      \r",
      "/ [7/25 objects]  28% Done                                                      \r",
      "/ [8/25 objects]  32% Done                                                      \r",
      "/ [9/25 objects]  36% Done                                                      \r",
      "/ [10/25 objects]  40% Done                                                     \r",
      "/ [11/25 objects]  44% Done                                                     \r",
      "/ [12/25 objects]  48% Done                                                     \r",
      "/ [13/25 objects]  52% Done                                                     \r",
      "/ [14/25 objects]  56% Done                                                     \r",
      "/ [15/25 objects]  60% Done                                                     \r",
      "/ [16/25 objects]  64% Done                                                     \r",
      "/ [17/25 objects]  68% Done                                                     \r",
      "/ [18/25 objects]  72% Done                                                     \r",
      "/ [19/25 objects]  76% Done                                                     \r",
      "/ [20/25 objects]  80% Done                                                     \r",
      "/ [21/25 objects]  84% Done                                                     \r",
      "/ [22/25 objects]  88% Done                                                     \r",
      "/ [23/25 objects]  92% Done                                                     \r",
      "/ [24/25 objects]  96% Done                                                     \r",
      "/ [25/25 objects] 100% Done                                                     \r\n",
      "Operation completed over 25 objects.                                             \n",
      "Job [brem_energy_forecast_linear_180917_233043] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe brem_energy_forecast_linear_180917_233043\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs brem_energy_forecast_linear_180917_233043\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/#1537226499067185...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/checkpoint#1537226501372848...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/eval/#1537226483288519...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/eval/events.out.tfevents.1537226484.cmle-training-17523491074583700031#1537226505209414...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/export/exporter/1537226486/variables/variables.data-00000-of-00001#1537226495320137...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/export/#1537226487470226...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/export/exporter/#1537226487782212...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/export/exporter/1537226486/#1537226494234780...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/export/exporter/1537226486/saved_model.pb#1537226494599744...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/export/exporter/1537226486/variables/variables.index#1537226495673888...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/export/exporter/1537226505/#1537226512387530...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/export/exporter/1537226505/saved_model.pb#1537226512922096...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/export/exporter/1537226505/variables/#1537226513235015...\n",
      "/ [1/25 objects]   4% Done                                                      \r",
      "/ [2/25 objects]   8% Done                                                      \r",
      "/ [3/25 objects]  12% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/export/exporter/1537226505/variables/variables.data-00000-of-00001#1537226513534255...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/export/exporter/1537226505/variables/variables.index#1537226513878447...\n",
      "/ [4/25 objects]  16% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/graph.pbtxt#1537226473385526...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/model.ckpt-1.data-00000-of-00001#1537226477346583...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/events.out.tfevents.1537226470.cmle-training-17523491074583700031#1537226503133312...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/model.ckpt-1.index#1537226477805935...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/export/exporter/1537226486/variables/#1537226494989842...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/model.ckpt-1.meta#1537226480573960...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/model.ckpt-30.data-00000-of-00001#1537226499660980...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/model.ckpt-30.index#1537226500255023...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/model.ckpt-30.meta#1537226502579105...\n",
      "Removing gs://atos-asl/bram/energy_forecast/dnn/packages/642a62172f7007d11bf90a431e9181e4c11747042814377b81b4b25778634b67/train-0.0.0.tar.gz#1537226373804158...\n",
      "/ [5/25 objects]  20% Done                                                      \r",
      "/ [6/25 objects]  24% Done                                                      \r",
      "/ [7/25 objects]  28% Done                                                      \r",
      "/ [8/25 objects]  32% Done                                                      \r",
      "/ [9/25 objects]  36% Done                                                      \r",
      "/ [10/25 objects]  40% Done                                                     \r",
      "/ [11/25 objects]  44% Done                                                     \r",
      "/ [12/25 objects]  48% Done                                                     \r",
      "/ [13/25 objects]  52% Done                                                     \r",
      "/ [14/25 objects]  56% Done                                                     \r",
      "/ [15/25 objects]  60% Done                                                     \r",
      "/ [16/25 objects]  64% Done                                                     \r",
      "/ [17/25 objects]  68% Done                                                     \r",
      "/ [18/25 objects]  72% Done                                                     \r",
      "/ [19/25 objects]  76% Done                                                     \r",
      "/ [20/25 objects]  80% Done                                                     \r",
      "/ [21/25 objects]  84% Done                                                     \r",
      "/ [22/25 objects]  88% Done                                                     \r",
      "/ [23/25 objects]  92% Done                                                     \r",
      "/ [24/25 objects]  96% Done                                                     \r",
      "/ [25/25 objects] 100% Done                                                     \r\n",
      "Operation completed over 25 objects.                                             \n",
      "Job [brem_energy_forecast_dnn_180917_233048] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe brem_energy_forecast_dnn_180917_233048\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs brem_energy_forecast_dnn_180917_233048\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/#1537226479084744...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/checkpoint#1537226481351114...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/eval/#1537226465281575...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/eval/events.out.tfevents.1537226465.cmle-training-7020605116498619201#1537226484909191...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/events.out.tfevents.1537226453.cmle-training-7020605116498619201#1537226482943082...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/export/#1537226467840930...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/export/exporter/#1537226468124467...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/export/exporter/1537226466/#1537226474268856...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/export/exporter/1537226466/saved_model.pb#1537226474595854...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/export/exporter/1537226466/variables/#1537226474907856...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/export/exporter/1537226466/variables/variables.data-00000-of-00001#1537226475312369...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/export/exporter/1537226466/variables/variables.index#1537226475729619...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/export/exporter/1537226485/#1537226491943868...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/export/exporter/1537226485/saved_model.pb#1537226492276476...\n",
      "/ [1/25 objects]   4% Done                                                      \r",
      "/ [2/25 objects]   8% Done                                                      \r",
      "/ [3/25 objects]  12% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/export/exporter/1537226485/variables/variables.data-00000-of-00001#1537226492941006...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/export/exporter/1537226485/variables/#1537226492599186...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/export/exporter/1537226485/variables/variables.index#1537226493277553...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/graph.pbtxt#1537226456046903...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/model.ckpt-1.data-00000-of-00001#1537226459999010...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/model.ckpt-1.index#1537226460524146...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/model.ckpt-1.meta#1537226462804883...\n",
      "/ [4/25 objects]  16% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/model.ckpt-30.data-00000-of-00001#1537226479629723...\n",
      "/ [5/25 objects]  20% Done                                                      \r",
      "/ [6/25 objects]  24% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/model.ckpt-30.index#1537226480203917...\n",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/model.ckpt-30.meta#1537226482336270...\n",
      "/ [7/25 objects]  28% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/cnn/packages/20384e01c8de4c889ff24b7951f9c42b5430639fbbcf5fdeab40080c0d4da875/train-0.0.0.tar.gz#1537226378504869...\n",
      "/ [8/25 objects]  32% Done                                                      \r",
      "/ [9/25 objects]  36% Done                                                      \r",
      "/ [10/25 objects]  40% Done                                                     \r",
      "/ [11/25 objects]  44% Done                                                     \r",
      "/ [12/25 objects]  48% Done                                                     \r",
      "/ [13/25 objects]  52% Done                                                     \r",
      "/ [14/25 objects]  56% Done                                                     \r",
      "/ [15/25 objects]  60% Done                                                     \r",
      "/ [16/25 objects]  64% Done                                                     \r",
      "/ [17/25 objects]  68% Done                                                     \r",
      "/ [18/25 objects]  72% Done                                                     \r",
      "/ [19/25 objects]  76% Done                                                     \r",
      "/ [20/25 objects]  80% Done                                                     \r",
      "/ [21/25 objects]  84% Done                                                     \r",
      "/ [22/25 objects]  88% Done                                                     \r",
      "/ [23/25 objects]  92% Done                                                     \r",
      "/ [24/25 objects]  96% Done                                                     \r",
      "/ [25/25 objects] 100% Done                                                     \r\n",
      "Operation completed over 25 objects.                                             \n",
      "Job [brem_energy_forecast_cnn_180917_233052] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe brem_energy_forecast_cnn_180917_233052\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs brem_energy_forecast_cnn_180917_233052\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/#1537226499749338...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/checkpoint#1537226501967236...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/eval/#1537226484329181...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/eval/events.out.tfevents.1537226484.cmle-training-4967998929067789755#1537226505719247...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/export/#1537226487035908...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/export/exporter/1537226485/#1537226494141494...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/events.out.tfevents.1537226471.cmle-training-4967998929067789755#1537226503587651...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/export/exporter/1537226485/saved_model.pb#1537226494489656...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/export/exporter/#1537226487361199...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/export/exporter/1537226485/variables/variables.data-00000-of-00001#1537226495348624...\n",
      "/ [1/25 objects]   4% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/export/exporter/1537226506/variables/variables.data-00000-of-00001#1537226514075820...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/export/exporter/1537226506/variables/variables.index#1537226514488956...\n",
      "/ [2/25 objects]   8% Done                                                      \r",
      "/ [3/25 objects]  12% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/export/exporter/1537226485/variables/variables.index#1537226495681134...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/export/exporter/1537226506/#1537226513061684...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/export/exporter/1537226506/saved_model.pb#1537226513386351...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/graph.pbtxt#1537226474074601...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/model.ckpt-1.data-00000-of-00001#1537226478761007...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/export/exporter/1537226485/variables/#1537226494900438...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/export/exporter/1537226506/variables/#1537226513718528...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/model.ckpt-1.index#1537226479380764...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/model.ckpt-1.meta#1537226481849545...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/model.ckpt-30.data-00000-of-00001#1537226500244466...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/model.ckpt-30.index#1537226500814946...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/model.ckpt-30.meta#1537226503097940...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn/packages/eb2018c57cfc79e16abcd1fb02981122314ad113cd33d37f6e183c8f38fba075/train-0.0.0.tar.gz#1537226383246584...\n",
      "/ [4/25 objects]  16% Done                                                      \r",
      "/ [5/25 objects]  20% Done                                                      \r",
      "/ [6/25 objects]  24% Done                                                      \r",
      "/ [7/25 objects]  28% Done                                                      \r",
      "/ [8/25 objects]  32% Done                                                      \r",
      "/ [9/25 objects]  36% Done                                                      \r",
      "/ [10/25 objects]  40% Done                                                     \r",
      "/ [11/25 objects]  44% Done                                                     \r",
      "/ [12/25 objects]  48% Done                                                     \r",
      "/ [13/25 objects]  52% Done                                                     \r",
      "/ [14/25 objects]  56% Done                                                     \r",
      "/ [15/25 objects]  60% Done                                                     \r",
      "/ [16/25 objects]  64% Done                                                     \r",
      "/ [17/25 objects]  68% Done                                                     \r",
      "/ [18/25 objects]  72% Done                                                     \r",
      "/ [19/25 objects]  76% Done                                                     \r",
      "/ [20/25 objects]  80% Done                                                     \r",
      "/ [21/25 objects]  84% Done                                                     \r",
      "/ [22/25 objects]  88% Done                                                     \r",
      "/ [23/25 objects]  92% Done                                                     \r",
      "/ [24/25 objects]  96% Done                                                     \r",
      "/ [25/25 objects] 100% Done                                                     \r\n",
      "Operation completed over 25 objects.                                             \n",
      "Job [brem_energy_forecast_rnn_180917_233057] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe brem_energy_forecast_rnn_180917_233057\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs brem_energy_forecast_rnn_180917_233057\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/#1537226500272128...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/checkpoint#1537226502627239...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/eval/#1537226484770944...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/eval/events.out.tfevents.1537226484.cmle-training-16806144332170335710#1537226506160117...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/events.out.tfevents.1537226472.cmle-training-16806144332170335710#1537226504350062...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/export/#1537226487645767...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/export/exporter/#1537226487979030...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/export/exporter/1537226486/#1537226494335073...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/export/exporter/1537226486/saved_model.pb#1537226494668338...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/export/exporter/1537226486/variables/#1537226495010386...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/export/exporter/1537226486/variables/variables.data-00000-of-00001#1537226495325889...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/export/exporter/1537226486/variables/variables.index#1537226495661110...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/export/exporter/1537226506/#1537226513512945...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/export/exporter/1537226506/saved_model.pb#1537226513922578...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/export/exporter/1537226506/variables/#1537226514256055...\n",
      "/ [1/25 objects]   4% Done                                                      \r",
      "/ [2/25 objects]   8% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/export/exporter/1537226506/variables/variables.data-00000-of-00001#1537226514585801...\n",
      "/ [3/25 objects]  12% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/export/exporter/1537226506/variables/variables.index#1537226514928630...\n",
      "/ [4/25 objects]  16% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/graph.pbtxt#1537226475128599...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/model.ckpt-1.data-00000-of-00001#1537226479250571...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/model.ckpt-1.index#1537226479806428...\n",
      "/ [5/25 objects]  20% Done                                                      \r",
      "/ [6/25 objects]  24% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/model.ckpt-1.meta#1537226482106413...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/model.ckpt-30.data-00000-of-00001#1537226500759419...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/model.ckpt-30.index#1537226501289035...\n",
      "/ [7/25 objects]  28% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/model.ckpt-30.meta#1537226503746175...\n",
      "/ [8/25 objects]  32% Done                                                      \r",
      "/ [9/25 objects]  36% Done                                                      \r",
      "/ [10/25 objects]  40% Done                                                     \r",
      "Removing gs://atos-asl/bram/energy_forecast/rnn2/packages/3400150f5cc7ca2692620956dd2ae1ed531b5c46ce47ce0ad882da15ccf5bf28/train-0.0.0.tar.gz#1537226387799893...\n",
      "/ [11/25 objects]  44% Done                                                     \r",
      "/ [12/25 objects]  48% Done                                                     \r",
      "/ [13/25 objects]  52% Done                                                     \r",
      "/ [14/25 objects]  56% Done                                                     \r",
      "/ [15/25 objects]  60% Done                                                     \r",
      "/ [16/25 objects]  64% Done                                                     \r",
      "/ [17/25 objects]  68% Done                                                     \r",
      "/ [18/25 objects]  72% Done                                                     \r",
      "/ [19/25 objects]  76% Done                                                     \r",
      "/ [20/25 objects]  80% Done                                                     \r",
      "/ [21/25 objects]  84% Done                                                     \r",
      "/ [22/25 objects]  88% Done                                                     \r",
      "/ [23/25 objects]  92% Done                                                     \r",
      "/ [24/25 objects]  96% Done                                                     \r",
      "/ [25/25 objects] 100% Done                                                     \r\n",
      "Operation completed over 25 objects.                                             \n",
      "Job [brem_energy_forecast_rnn2_180917_233102] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe brem_energy_forecast_rnn2_180917_233102\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs brem_energy_forecast_rnn2_180917_233102\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/#1537226517051082...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/checkpoint#1537226519051958...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/eval/#1537226502043169...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/eval/events.out.tfevents.1537226502.cmle-training-6279933638860278588#1537226523219085...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/events.out.tfevents.1537226488.cmle-training-6279933638860278588#1537226521126080...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/export/#1537226505006738...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/export/exporter/#1537226505353100...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/export/exporter/1537226504/#1537226511465401...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/export/exporter/1537226504/saved_model.pb#1537226511772815...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/export/exporter/1537226504/variables/#1537226512185317...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/export/exporter/1537226504/variables/variables.data-00000-of-00001#1537226512526029...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/export/exporter/1537226504/variables/variables.index#1537226512846842...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/export/exporter/1537226523/#1537226530247943...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/export/exporter/1537226523/saved_model.pb#1537226530573887...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/export/exporter/1537226523/variables/#1537226530960508...\n",
      "/ [1/25 objects]   4% Done                                                      \r",
      "/ [2/25 objects]   8% Done                                                      \r",
      "/ [3/25 objects]  12% Done                                                      \r",
      "/ [4/25 objects]  16% Done                                                      \r",
      "/ [5/25 objects]  20% Done                                                      \r",
      "/ [6/25 objects]  24% Done                                                      \r",
      "/ [7/25 objects]  28% Done                                                      \r",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/export/exporter/1537226523/variables/variables.data-00000-of-00001#1537226531296522...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/export/exporter/1537226523/variables/variables.index#1537226531619747...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/graph.pbtxt#1537226490995172...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/model.ckpt-1.meta#1537226499268417...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/model.ckpt-30.data-00000-of-00001#1537226517573120...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/model.ckpt-30.index#1537226518103716...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/model.ckpt-1.data-00000-of-00001#1537226496546041...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/model.ckpt-30.meta#1537226520299383...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/model.ckpt-1.index#1537226497092039...\n",
      "Removing gs://atos-asl/bram/energy_forecast/rnnN/packages/a52c5f562ccf026c7d40bf0fe224e7c46bcb1604c95939b66cc62c52f91e93ec/train-0.0.0.tar.gz#1537226392396982...\n",
      "/ [8/25 objects]  32% Done                                                      \r",
      "/ [9/25 objects]  36% Done                                                      \r",
      "/ [10/25 objects]  40% Done                                                     \r",
      "/ [11/25 objects]  44% Done                                                     \r",
      "/ [12/25 objects]  48% Done                                                     \r",
      "/ [13/25 objects]  52% Done                                                     \r",
      "/ [14/25 objects]  56% Done                                                     \r",
      "/ [15/25 objects]  60% Done                                                     \r",
      "/ [16/25 objects]  64% Done                                                     \r",
      "/ [17/25 objects]  68% Done                                                     \r",
      "/ [18/25 objects]  72% Done                                                     \r",
      "/ [19/25 objects]  76% Done                                                     \r",
      "/ [20/25 objects]  80% Done                                                     \r",
      "/ [21/25 objects]  84% Done                                                     \r",
      "/ [22/25 objects]  88% Done                                                     \r",
      "/ [23/25 objects]  92% Done                                                     \r",
      "/ [24/25 objects]  96% Done                                                     \r",
      "/ [25/25 objects] 100% Done                                                     \r\n",
      "Operation completed over 25 objects.                                             \n",
      "Job [brem_energy_forecast_rnnN_180917_233106] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe brem_energy_forecast_rnnN_180917_233106\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs brem_energy_forecast_rnnN_180917_233106\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "SEQ_LEN=24\n",
    "TFVERSION='1.8'\n",
    "for MODEL in linear dnn cnn rnn rnn2 rnnN; do\n",
    "  OUTDIR=gs://${BUCKET}/bram/energy_forecast/${MODEL}\n",
    "  JOBNAME=brem_energy_forecast_${MODEL}_$(date -u +%y%m%d_%H%M%S)\n",
    "  REGION=us-central1\n",
    "  gsutil -m rm -rf $OUTDIR\n",
    "  gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "     --region=$REGION \\\n",
    "     --module-name=train.task \\\n",
    "     --package-path=${PWD}/train \\\n",
    "     --job-dir=$OUTDIR \\\n",
    "     --scale-tier=BASIC \\\n",
    "     --runtime-version=$TFVERSION \\\n",
    "     -- \\\n",
    "     --train_data_path=\"gs://${BUCKET}/bram/daily/*train*.csv\" \\\n",
    "     --eval_data_path=\"gs://${BUCKET}/bram/daily/*eval*.csv\"  \\\n",
    "     --output_dir=$OUTDIR \\\n",
    "     --train_steps=3000 \\\n",
    "     --sequence_length=$SEQ_LEN \\\n",
    "     --model=$MODEL\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2018-09-17T23:19:52Z'\n",
      "etag: b01Bi7ZIgK4=\n",
      "jobId: brem_energy_forecast_rnnN_180917_231948\n",
      "startTime: '2018-09-17T23:20:32Z'\n",
      "state: RUNNING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --train_data_path=gs://atos-asl/bram/daily/*train*.csv\n",
      "  - --eval_data_path=gs://atos-asl/bram/daily/*eval*.csv\n",
      "  - --output_dir=gs://atos-asl/bram/energy_forecast/rnnN\n",
      "  - --train_steps=30\n",
      "  - --sequence_length=24\n",
      "  - --model=rnnN\n",
      "  jobDir: gs://atos-asl/bram/energy_forecast/rnnN\n",
      "  packageUris:\n",
      "  - gs://atos-asl/bram/energy_forecast/rnnN/packages/a52c5f562ccf026c7d40bf0fe224e7c46bcb1604c95939b66cc62c52f91e93ec/train-0.0.0.tar.gz\n",
      "  pythonModule: train.task\n",
      "  region: us-central1\n",
      "  runtimeVersion: '1.8'\n",
      "trainingOutput:\n",
      "  consumedMLUnits: 0.02\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/ml/jobs/brem_energy_forecast_rnnN_180917_231948?project=qwiklabs-gcp-aebfb78fe0f1b1d1\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fbrem_energy_forecast_rnnN_180917_231948&project=qwiklabs-gcp-aebfb78fe0f1b1d1\n"
     ]
    }
   ],
   "source": [
    "! gcloud ml-engine jobs describe brem_energy_forecast_rnnN_180917_231948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 38045. Click <a href=\"/_proxy/44175/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "38045"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('gs://{}/bram/energy_forecast'.format(BUCKET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped TensorBoard with pid 14748\n"
     ]
    }
   ],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://atos-asl/datasets/timeserie_price_daily_train_fix.csv...\n",
      "/ [0 files][    0.0 B/ 30.6 KiB]                                                \r",
      "/ [1 files][ 30.6 KiB/ 30.6 KiB]                                                \r\n",
      "Operation completed over 1 objects/30.6 KiB.                                     \n",
      "Copying gs://atos-asl/datasets/timeserie_price_daily_eval_fix.csv...\n",
      "/ [0 files][    0.0 B/  5.9 KiB]                                                \r",
      "/ [1 files][  5.9 KiB/  5.9 KiB]                                                \r\n",
      "Operation completed over 1 objects/5.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm ./data/timeserie_price_daily_train.csv\n",
    "rm ./data/timeserie_price_daily_eval.csv\n",
    "gsutil cp gs://atos-asl/datasets/timeserie_price_daily_train_fix.csv ./data/timeserie_price_daily_train.csv\n",
    "gsutil cp gs://atos-asl/datasets/timeserie_price_daily_eval_fix.csv ./data/timeserie_price_daily_eval.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [48.1, 42.27, 35.72, 35.13, 36.22, 32.4, 36.6, 43.1, 45.14, 45.14.1, 47.35, 47.35.1, 44.91, 48.1.1, 58.02, 61.01, 62.69, 58.15, 53.6, 47.34, 40.4, 36.0, 37.0, 37.98]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 24 columns]\n",
      "(222, 24)\n",
      "24\n",
      "(222, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>48.1</th>\n",
       "      <th>42.27</th>\n",
       "      <th>35.72</th>\n",
       "      <th>35.13</th>\n",
       "      <th>36.22</th>\n",
       "      <th>32.4</th>\n",
       "      <th>36.6</th>\n",
       "      <th>43.1</th>\n",
       "      <th>45.14</th>\n",
       "      <th>45.14.1</th>\n",
       "      <th>...</th>\n",
       "      <th>58.02</th>\n",
       "      <th>61.01</th>\n",
       "      <th>62.69</th>\n",
       "      <th>58.15</th>\n",
       "      <th>53.6</th>\n",
       "      <th>47.34</th>\n",
       "      <th>40.4</th>\n",
       "      <th>36.0</th>\n",
       "      <th>37.0</th>\n",
       "      <th>37.98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [48.1, 42.27, 35.72, 35.13, 36.22, 32.4, 36.6, 43.1, 45.14, 45.14.1, 47.35, 47.35.1, 44.91, 48.1.1, 58.02, 61.01, 62.69, 58.15, 53.6, 47.34, 40.4, 36.0, 37.0, 37.98]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "df = pd.read_csv('./data/timeserie_price_daily_train.csv')\n",
    "print(df[df.isnull().any(axis=1)])\n",
    "print(df.shape)\n",
    "print(len(df.any().isna()))\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 ./data/timeserie_price_daily_eval.csv\n",
      "46.58,46.58,46.69,47.63,50.54,59.6,61.04,61.38,61.69,61.04,60.73,60.01,58.0,55.0,55.6,56.8,59.59,60.5,63.5,61.69,59.0,52.62,54.0,50.89\n",
      "47.74,46.3,43.97,43.0,43.15,44.0,46.3,53.11,52.42,48.7,47.63,47.63,46.3,44.08,43.5,44.84,50.0,52.37,58.95,56.6,50.3,49.85,50.52,44.97\n",
      "41.0,39.58,39.5,39.67,40.53,41.6,41.0,46.3,50.0,50.1,50.0,50.0,49.02,44.86,41.74,42.58,44.47,50.73,61.0,61.74,57.5,50.1,45.15,39.75\n",
      "38.75,38.2,37.7,37.58,43.45,50.3,51.75,53.11,50.3,49.02,50.52,51.02,50.52,48.06,46.54,47.38,53.33,57.83,58.75,56.02,48.9,46.3,40.0,38.1\n",
      "37.0,36.5,36.5,37.2,44.01,54.28,54.69,55.15,54.61,54.11,55.11,54.69,54.5,54.11,55.0,54.69,55.11,60.73,60.73,56.57,50.1,46.3,40.2,39.25\n",
      "38.35,36.0,36.0,38.35,46.05,54.0,55.6,55.16,54.19,53.4,54.0,53.91,53.55,52.19,52.28,53.19,56.28,59.02,59.17,56.0,51.1,46.6,43.97,40.24\n",
      "39.53,40.0,39.53,40.24,46.29,57.72,61.35,63.1,62.97,60.1,59.59,58.64,56.7,56.02,56.02,56.6,57.78,63.61,65.48,63.03,59.0,55.16,56.8,55.02\n",
      "52.0,52.0,50.0,52.5,56.7,63.14,63.6,64.8,64.68,62.99,59.71,57.44,56.7,55.25,55.75,56.7,59.87,63.03,65.01,60.98,56.8,50.5,56.6,47.61\n",
      "46.58,43.59,40.34,38.0,39.98,43.08,46.64,48.13,48.28,47.21,47.15,44.63,42.09,39.74,39.18,42.6,48.8,50.5,52.86,50.0,44.64,43.85,45.15,42.58\n",
      "40.0,40.69,41.0,41.87,43.09,45.0,44.02,47.21,54.0,55.8,56.7,56.7,55.8,47.76,46.82,43.85,47.44,56.05,60.01,60.17,58.81,56.57,47.61,46.68\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc -l ./data/timeserie_price_daily_eval.csv\n",
    "tail ./data/timeserie_price_daily_eval.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([61.35,58.64,56.7,65.48,63.03,52.0,64.8,56.7,60.98,43.08,47.21,39.74,42.6,40.0,41.87,47.21,54.0,56.7,55.8,46.68,42.95,48.75,60.01,60.17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
